{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import and Install Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mediapipe in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (0.10.7)\n",
      "Requirement already satisfied: absl-py in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (from mediapipe) (2.0.0)\n",
      "Requirement already satisfied: attrs>=19.1.0 in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (from mediapipe) (23.1.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (from mediapipe) (23.5.26)\n",
      "Requirement already satisfied: matplotlib in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (from mediapipe) (3.8.0)\n",
      "Requirement already satisfied: numpy in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (from mediapipe) (1.26.0)\n",
      "Requirement already satisfied: opencv-contrib-python in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (from mediapipe) (4.8.1.78)\n",
      "Requirement already satisfied: protobuf<4,>=3.11 in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (from mediapipe) (3.20.3)\n",
      "Requirement already satisfied: sounddevice>=0.4.4 in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (from mediapipe) (0.4.6)\n",
      "Requirement already satisfied: CFFI>=1.0 in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (from sounddevice>=0.4.4->mediapipe) (1.16.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (from matplotlib->mediapipe) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (from matplotlib->mediapipe) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (from matplotlib->mediapipe) (4.43.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (from matplotlib->mediapipe) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (from matplotlib->mediapipe) (23.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (from matplotlib->mediapipe) (10.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (from matplotlib->mediapipe) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (from matplotlib->mediapipe) (2.8.2)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (from matplotlib->mediapipe) (6.1.0)\n",
      "Requirement already satisfied: pycparser in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.21)\n",
      "Requirement already satisfied: zipp>=3.1.0 in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib->mediapipe) (3.17.0)\n",
      "Requirement already satisfied: six>=1.5 in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow==2.14.0 in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (2.14.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.14.0 in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (from tensorflow==2.14.0) (2.14.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow==2.14.0) (2.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow==2.14.0) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow==2.14.0) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow==2.14.0) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow==2.14.0) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow==2.14.0) (3.10.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow==2.14.0) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes==0.2.0 in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow==2.14.0) (0.2.0)\n",
      "Requirement already satisfied: numpy>=1.23.5 in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow==2.14.0) (1.26.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow==2.14.0) (3.3.0)\n",
      "Requirement already satisfied: packaging in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow==2.14.0) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow==2.14.0) (3.20.3)\n",
      "Requirement already satisfied: setuptools in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow==2.14.0) (58.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow==2.14.0) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow==2.14.0) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow==2.14.0) (4.8.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow==2.14.0) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow==2.14.0) (0.31.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow==2.14.0) (1.59.0)\n",
      "Requirement already satisfied: tensorboard<2.15,>=2.14 in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow==2.14.0) (2.14.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow==2.14.0) (2.14.0)\n",
      "Requirement already satisfied: keras<2.15,>=2.14.0 in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow==2.14.0) (2.14.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.14.0->tensorflow==2.14.0) (0.41.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow==2.14.0) (2.23.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow==2.14.0) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow==2.14.0) (3.5)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow==2.14.0) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow==2.14.0) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow==2.14.0) (3.0.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow==2.14.0) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow==2.14.0) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow==2.14.0) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow==2.14.0) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow==2.14.0) (6.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow==2.14.0) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow==2.14.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow==2.14.0) (2.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow==2.14.0) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow==2.14.0) (2.1.3)\n",
      "Requirement already satisfied: zipp>=0.5 in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow==2.14.0) (3.17.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow==2.14.0) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow==2.14.0) (3.2.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (4.8.1.78)\n",
      "Requirement already satisfied: numpy>=1.17.0 in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (from opencv-python) (1.26.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mediapipe in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (0.10.7)\n",
      "Requirement already satisfied: absl-py in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (from mediapipe) (2.0.0)\n",
      "Requirement already satisfied: attrs>=19.1.0 in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (from mediapipe) (23.1.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (from mediapipe) (23.5.26)\n",
      "Requirement already satisfied: matplotlib in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (from mediapipe) (3.8.0)\n",
      "Requirement already satisfied: numpy in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (from mediapipe) (1.26.0)\n",
      "Requirement already satisfied: opencv-contrib-python in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (from mediapipe) (4.8.1.78)\n",
      "Requirement already satisfied: protobuf<4,>=3.11 in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (from mediapipe) (3.20.3)\n",
      "Requirement already satisfied: sounddevice>=0.4.4 in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (from mediapipe) (0.4.6)\n",
      "Requirement already satisfied: CFFI>=1.0 in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (from sounddevice>=0.4.4->mediapipe) (1.16.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (from matplotlib->mediapipe) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (from matplotlib->mediapipe) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (from matplotlib->mediapipe) (4.43.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (from matplotlib->mediapipe) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (from matplotlib->mediapipe) (23.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (from matplotlib->mediapipe) (10.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (from matplotlib->mediapipe) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (from matplotlib->mediapipe) (2.8.2)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (from matplotlib->mediapipe) (6.1.0)\n",
      "Requirement already satisfied: pycparser in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.21)\n",
      "Requirement already satisfied: zipp>=3.1.0 in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib->mediapipe) (3.17.0)\n",
      "Requirement already satisfied: six>=1.5 in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (3.8.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (from matplotlib) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (from matplotlib) (4.43.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (from matplotlib) (1.26.0)\n",
      "Requirement already satisfied: packaging>=20.0 in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (from matplotlib) (10.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (from matplotlib) (6.1.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib) (3.17.0)\n",
      "Requirement already satisfied: six>=1.5 in e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\code\\studia\\engineeringthesis\\venv\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install mediapipe\n",
    "!pip install tensorflow==2.14.0\n",
    "!pip install opencv-python\n",
    "!pip install mediapipe\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run preps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import mediapipe as mp\n",
    "from tensorflow import keras\n",
    "import tensorflow\n",
    "from sklearn.metrics import multilabel_confusion_matrix, accuracy_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "mp_holistic = mp.solutions.holistic # Holistic model\n",
    "mp_drawing = mp.solutions.drawing_utils # Drawing utilities\n",
    "\n",
    "def mediapipe_detection(image, model):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # COLOR CONVERSION BGR 2 RGB\n",
    "    image.flags.writeable = False                  # Image is no longer writeable\n",
    "    results = model.process(image)                 # Make prediction\n",
    "    image.flags.writeable = True                   # Image is now writeable \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR) # COLOR COVERSION RGB 2 BGR\n",
    "    return image, results\n",
    "\n",
    "def draw_landmarks(image, results):\n",
    "    mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_CONTOURS) # Draw face connections\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS) # Draw pose connections\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS) # Draw left hand connections\n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS) # Draw right hand connections\n",
    "\n",
    "def draw_styled_landmarks(image, results):\n",
    "    # Draw face connections\n",
    "    mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_CONTOURS, \n",
    "                             mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1), \n",
    "                             mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n",
    "                             ) \n",
    "    # Draw pose connections\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4), \n",
    "                             mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "                             ) \n",
    "    # Draw left hand connections\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                             mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4), \n",
    "                             mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "                             ) \n",
    "    # Draw right hand connections  \n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                             mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4), \n",
    "                             mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                             )\n",
    "    \n",
    "def extract_keypoints(results):\n",
    "    pose = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(33*4)\n",
    "    face = np.array([[res.x, res.y, res.z] for res in results.face_landmarks.landmark]).flatten() if results.face_landmarks else np.zeros(468*3)\n",
    "    lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n",
    "    rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)\n",
    "    return np.concatenate([pose, lh, rh])\n",
    "\n",
    "def rename_dirs(starting_pos):\n",
    "    all_data_dir_path = os.path.join(os.getcwd(), 'MP_Data')\n",
    "    \n",
    "    activities_dirs = [name for name in os.listdir(all_data_dir_path) if os.path.isdir(os.path.join(all_data_dir_path, name))]\n",
    "    \n",
    "    if not len(activities_dirs):\n",
    "        return\n",
    "    \n",
    "    # Get the current directory\n",
    "    for activity_dir_name in activities_dirs:\n",
    "        banned_names = [\"move_left\", \"move_right\", \"pc_lock\", \"pc_on\"]\n",
    "        if activity_dir_name in banned_names:\n",
    "            continue\n",
    "        activity_dir_path = os.path.join(all_data_dir_path, activity_dir_name)\n",
    "    \n",
    "        # List all directories in the current location\n",
    "        activity_dir_enumerated_dirs = [num_name for num_name in os.listdir(activity_dir_path) if os.path.isdir(os.path.join(activity_dir_path, num_name))]\n",
    "\n",
    "    \n",
    "        if starting_pos > 0:\n",
    "            activity_dir_enumerated_dirs.sort(reverse=True, key=int)\n",
    "        else:\n",
    "            activity_dir_enumerated_dirs.sort(reverse=False, key=int)\n",
    "\n",
    "        # Rename the directories\n",
    "        for directory_num_name in activity_dir_enumerated_dirs:\n",
    "            new_name = int(directory_num_name) + int(starting_pos)\n",
    "            os.rename(os.path.join(activity_dir_path, str(directory_num_name)), os.path.join(activity_dir_path, str(new_name)))\n",
    "\n",
    "def prob_viz(res, actions, input_frame, colors):\n",
    "    output_frame = input_frame.copy()\n",
    "    for num, prob in enumerate(res):\n",
    "        cv2.rectangle(output_frame, (0,60+num*40), (int(prob*100), 90+num*40), colors[num], -1)\n",
    "        cv2.putText(output_frame, actions[num], (0, 85+num*40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)\n",
    "        \n",
    "    return output_frame\n",
    "\n",
    "colors = [(245,117,16), (117,245,16), (16,117,245), (1,100,200), (10,50,70), (1,150,30)]\n",
    "\n",
    "# Path for exported data, numpy arrays\n",
    "DATA_PATH = os.path.join('MP_Data') \n",
    "\n",
    "# Actions that we try to detect\n",
    "# actions = np.array(['pc_on', 'pc_lock', 'move_left', 'move_right', 'show_destkop', 'mute'])\n",
    "actions = np.array(['pc_on', 'pc_lock', 'move_left', 'move_right', 'show_destkop', 'mute'])\n",
    "\n",
    "# Thirty videos worth of data\n",
    "no_sequences = 30\n",
    "\n",
    "# Videos are going to be 30 frames in length\n",
    "sequence_length = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run test keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "# Set mediapipe model \n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "\n",
    "        # Read feed\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Make detections\n",
    "        image, results = mediapipe_detection(frame, holistic)\n",
    "        print(results)\n",
    "        \n",
    "        # Draw landmarks\n",
    "        draw_styled_landmarks(image, results)\n",
    "\n",
    "        # Show to screen\n",
    "        cv2.imshow('OpenCV Feed', image)\n",
    "\n",
    "        # Break gracefully\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manage folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for action in actions: \n",
    "    for sequence in range(no_sequences):\n",
    "        try: \n",
    "            os.makedirs(os.path.join(DATA_PATH, action, str(sequence)))\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_dirs(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect Keypoint Data for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "# Set mediapipe model \n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    \n",
    "    # NEW LOOP\n",
    "    # Loop through actions\n",
    "    for action in actions:\n",
    "        # Loop through sequences aka videos\n",
    "        for sequence in range(no_sequences):\n",
    "            # Loop through video length aka sequence length\n",
    "            for frame_num in range(sequence_length):\n",
    "\n",
    "                # Read feed\n",
    "                ret, frame = cap.read()\n",
    "\n",
    "                # Make detections\n",
    "                image, results = mediapipe_detection(frame, holistic)\n",
    "#                 print(results)\n",
    "\n",
    "                # Draw landmarks\n",
    "                draw_styled_landmarks(image, results)\n",
    "                \n",
    "                # NEW Apply wait logic\n",
    "                if frame_num == 0: \n",
    "                    cv2.putText(image, 'STARTING COLLECTION', (120,200), \n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255, 0), 4, cv2.LINE_AA)\n",
    "                    cv2.putText(image, 'Collecting frames for {} Video Number {}'.format(action, sequence), (15,12), \n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "                    # Show to screen\n",
    "                    cv2.imshow('OpenCV Feed', image)\n",
    "                    cv2.waitKey(700)\n",
    "                else: \n",
    "                    cv2.putText(image, 'Collecting frames for {} Video Number {}'.format(action, sequence), (15,12), \n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "                    # Show to screen\n",
    "                    cv2.imshow('OpenCV Feed', image)\n",
    "                \n",
    "                # NEW Export keypoints\n",
    "                keypoints = extract_keypoints(results)\n",
    "                npy_path = os.path.join(DATA_PATH, action, str(sequence), str(frame_num))\n",
    "                np.save(npy_path, keypoints)\n",
    "\n",
    "                # Break gracefully\n",
    "                if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                    break\n",
    "                    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build and Train LSTM Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {label:num for num, label in enumerate(actions)}\n",
    "sequences, labels = [], []\n",
    "\n",
    "# Define the number of sequences for each action\n",
    "no_sequences_per_action = {\n",
    "    'pc_on': 30,\n",
    "    'pc_lock': 30,\n",
    "    'move_left': 30,\n",
    "    'move_right': 30,\n",
    "    'show_desktop': 30,\n",
    "    'mute': 30\n",
    "}\n",
    "\n",
    "for action in actions:\n",
    "    no_sequences = no_sequences_per_action.get(action, 30)  # Default to 30 sequences if not specified\n",
    "    \n",
    "    for sequence in range(no_sequences):\n",
    "        window = []\n",
    "        for frame_num in range(sequence_length):\n",
    "            res = np.load(os.path.join(DATA_PATH, action, str(sequence), \"{}.npy\".format(frame_num)))\n",
    "            window.append(res)\n",
    "        sequences.append(window)\n",
    "        labels.append(label_map[action])\n",
    "\n",
    "np.save('sequences.npy', np.array(sequences, dtype=object), allow_pickle=True)\n",
    "np.save('labels.npy', np.array(labels, dtype=object), allow_pickle=True)\n",
    "\n",
    "y = to_categorical(labels).astype(int)\n",
    "X = np.array(sequences)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05)\n",
    "\n",
    "log_dir = os.path.join('Logs')\n",
    "tb_callback = TensorBoard(log_dir=log_dir)\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, return_sequences=True, activation='relu', input_shape=(30, 258), name='lstm_1'))\n",
    "model.add(LSTM(128, return_sequences=True, activation='relu', name='lstm_2'))\n",
    "model.add(LSTM(64, return_sequences=False, activation='relu', name='lstm_3'))\n",
    "model.add(Dense(64, activation='relu', name='dense_1'))\n",
    "model.add(Dense(32, activation='relu', name='dense_2'))\n",
    "model.add(Dense(actions.shape[0], activation='softmax', name='output_layer'))\n",
    "actions.shape[0]\n",
    "res = [.7, 0.2, 0.1]\n",
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1830, 30, 258)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(sequences).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "6/6 [==============================] - 4s 34ms/step - loss: 1.6959 - categorical_accuracy: 0.3099\n",
      "Epoch 2/100\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 1.4766 - categorical_accuracy: 0.4503\n",
      "Epoch 3/100\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 1.0708 - categorical_accuracy: 0.6433\n",
      "Epoch 4/100\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.6784 - categorical_accuracy: 0.8304\n",
      "Epoch 5/100\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.4495 - categorical_accuracy: 0.8304\n",
      "Epoch 6/100\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 0.2905 - categorical_accuracy: 0.8713\n",
      "Epoch 7/100\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.5482 - categorical_accuracy: 0.9298\n",
      "Epoch 8/100\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.3185 - categorical_accuracy: 0.9591\n",
      "Epoch 9/100\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.3322 - categorical_accuracy: 0.9415\n",
      "Epoch 10/100\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.2494 - categorical_accuracy: 0.9766\n",
      "Epoch 11/100\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.3144 - categorical_accuracy: 0.9708\n",
      "Epoch 12/100\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 0.2857 - categorical_accuracy: 0.9649\n",
      "Epoch 13/100\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.2715 - categorical_accuracy: 0.9532\n",
      "Epoch 14/100\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.2515 - categorical_accuracy: 0.9708\n",
      "Epoch 15/100\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.2466 - categorical_accuracy: 0.9708\n",
      "Epoch 16/100\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.2474 - categorical_accuracy: 0.9532\n",
      "Epoch 17/100\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 0.9945 - categorical_accuracy: 0.9357\n",
      "Epoch 18/100\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 0.2664 - categorical_accuracy: 0.9474\n",
      "Epoch 19/100\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 1.1464 - categorical_accuracy: 0.8655\n",
      "Epoch 20/100\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.3946 - categorical_accuracy: 0.8655\n",
      "Epoch 21/100\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.5128 - categorical_accuracy: 0.9298\n",
      "Epoch 22/100\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.3344 - categorical_accuracy: 0.9708\n",
      "Epoch 23/100\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.1934 - categorical_accuracy: 0.9883\n",
      "Epoch 24/100\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.0833 - categorical_accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.0441 - categorical_accuracy: 0.9942\n",
      "Epoch 26/100\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.0260 - categorical_accuracy: 0.9825\n",
      "Epoch 27/100\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.0107 - categorical_accuracy: 0.9942\n",
      "Epoch 28/100\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 0.0500 - categorical_accuracy: 0.9825\n",
      "Epoch 29/100\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.0474 - categorical_accuracy: 0.9942\n",
      "Epoch 30/100\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 0.0251 - categorical_accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.0298 - categorical_accuracy: 0.9942\n",
      "Epoch 32/100\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.0120 - categorical_accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.0095 - categorical_accuracy: 0.9942\n",
      "Epoch 34/100\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.0088 - categorical_accuracy: 0.9942\n",
      "Epoch 35/100\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.0079 - categorical_accuracy: 0.9942\n",
      "Epoch 36/100\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.0066 - categorical_accuracy: 0.9942\n",
      "Epoch 37/100\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.0037 - categorical_accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 0.0017 - categorical_accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 20.3764 - categorical_accuracy: 0.8596\n",
      "Epoch 40/100\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 118.1255 - categorical_accuracy: 0.7368\n",
      "Epoch 41/100\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 3.2786 - categorical_accuracy: 0.4971\n",
      "Epoch 42/100\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 1.3657 - categorical_accuracy: 0.4444\n",
      "Epoch 43/100\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 1.0937 - categorical_accuracy: 0.5322\n",
      "Epoch 44/100\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.8746 - categorical_accuracy: 0.6316\n",
      "Epoch 45/100\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.7120 - categorical_accuracy: 0.7076\n",
      "Epoch 46/100\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.5092 - categorical_accuracy: 0.7778\n",
      "Epoch 47/100\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.3685 - categorical_accuracy: 0.8129\n",
      "Epoch 48/100\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.2373 - categorical_accuracy: 0.9298\n",
      "Epoch 49/100\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.1954 - categorical_accuracy: 0.9415\n",
      "Epoch 50/100\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.1294 - categorical_accuracy: 0.9532\n",
      "Epoch 51/100\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.2348 - categorical_accuracy: 0.9357\n",
      "Epoch 52/100\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.3690 - categorical_accuracy: 0.9064\n",
      "Epoch 53/100\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.2558 - categorical_accuracy: 0.9064\n",
      "Epoch 54/100\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.1465 - categorical_accuracy: 0.9708\n",
      "Epoch 55/100\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.1148 - categorical_accuracy: 0.9883\n",
      "Epoch 56/100\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.0748 - categorical_accuracy: 0.9591\n",
      "Epoch 57/100\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 0.0382 - categorical_accuracy: 0.9883\n",
      "Epoch 58/100\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.1214 - categorical_accuracy: 0.9649\n",
      "Epoch 59/100\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.1269 - categorical_accuracy: 0.9591\n",
      "Epoch 60/100\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.1004 - categorical_accuracy: 0.9649\n",
      "Epoch 61/100\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.0456 - categorical_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 5.9494 - categorical_accuracy: 0.7427\n",
      "Epoch 63/100\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.7359 - categorical_accuracy: 0.7427\n",
      "Epoch 64/100\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.7497 - categorical_accuracy: 0.7485\n",
      "Epoch 65/100\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.6726 - categorical_accuracy: 0.7719\n",
      "Epoch 66/100\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.6431 - categorical_accuracy: 0.7719\n",
      "Epoch 67/100\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.6207 - categorical_accuracy: 0.7719\n",
      "Epoch 68/100\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.6026 - categorical_accuracy: 0.7719\n",
      "Epoch 69/100\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.5834 - categorical_accuracy: 0.7719\n",
      "Epoch 70/100\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.5637 - categorical_accuracy: 0.7719\n",
      "Epoch 71/100\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.5367 - categorical_accuracy: 0.7719\n",
      "Epoch 72/100\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.4740 - categorical_accuracy: 0.7719\n",
      "Epoch 73/100\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.6176 - categorical_accuracy: 0.7368\n",
      "Epoch 74/100\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.5385 - categorical_accuracy: 0.7719\n",
      "Epoch 75/100\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 0.5250 - categorical_accuracy: 0.7719\n",
      "Epoch 76/100\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.5301 - categorical_accuracy: 0.7602\n",
      "Epoch 77/100\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.9019 - categorical_accuracy: 0.6842\n",
      "Epoch 78/100\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 1.0930 - categorical_accuracy: 0.6667\n",
      "Epoch 79/100\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.6132 - categorical_accuracy: 0.7310\n",
      "Epoch 80/100\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.6232 - categorical_accuracy: 0.7310\n",
      "Epoch 81/100\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.5536 - categorical_accuracy: 0.7661\n",
      "Epoch 82/100\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.5321 - categorical_accuracy: 0.7661\n",
      "Epoch 83/100\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.5124 - categorical_accuracy: 0.7661\n",
      "Epoch 84/100\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.5010 - categorical_accuracy: 0.7661\n",
      "Epoch 85/100\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.4903 - categorical_accuracy: 0.7661\n",
      "Epoch 86/100\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.4788 - categorical_accuracy: 0.7661\n",
      "Epoch 87/100\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.4611 - categorical_accuracy: 0.7895\n",
      "Epoch 88/100\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 0.3444 - categorical_accuracy: 0.9181\n",
      "Epoch 89/100\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 55.9744 - categorical_accuracy: 0.8304\n",
      "Epoch 90/100\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 6.7077 - categorical_accuracy: 0.6901\n",
      "Epoch 91/100\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 7.0388 - categorical_accuracy: 0.5789\n",
      "Epoch 92/100\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 29.8915 - categorical_accuracy: 0.3158\n",
      "Epoch 93/100\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 13.8380 - categorical_accuracy: 0.3860\n",
      "Epoch 94/100\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 2.1663 - categorical_accuracy: 0.3684\n",
      "Epoch 95/100\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 1.1356 - categorical_accuracy: 0.4327\n",
      "Epoch 96/100\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 1.3140 - categorical_accuracy: 0.5380\n",
      "Epoch 97/100\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.9818 - categorical_accuracy: 0.6608\n",
      "Epoch 98/100\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.9546 - categorical_accuracy: 0.7076\n",
      "Epoch 99/100\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.8634 - categorical_accuracy: 0.6667\n",
      "Epoch 100/100\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.7376 - categorical_accuracy: 0.7076\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x232757ded90>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=100, callbacks=[tb_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save/Load model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_model.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.load('my_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('150rc4fun.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test in Real Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step\n",
      "[9.7643722e-05 8.8043146e-02 1.2627376e-02 4.7120773e-03 8.9286971e-01\n",
      " 1.6501526e-03]\n",
      "Gesture recognition percentage: 89.29%\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[1.0546311e-04 5.3038564e-02 9.3665402e-03 4.2012902e-03 9.3197882e-01\n",
      " 1.3092947e-03]\n",
      "Gesture recognition percentage: 93.2%\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[1.0881673e-04 3.1543180e-02 6.6312356e-03 3.5803311e-03 9.5708787e-01\n",
      " 1.0486711e-03]\n",
      "Gesture recognition percentage: 95.71%\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[1.0953290e-04 1.9146677e-02 4.6229693e-03 2.9918484e-03 9.7226602e-01\n",
      " 8.6297787e-04]\n",
      "Gesture recognition percentage: 97.23%\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[1.10865345e-04 1.35312853e-02 3.59753100e-03 2.63973232e-03\n",
      " 9.79357004e-01 7.63521937e-04]\n",
      "Gesture recognition percentage: 97.94%\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "[1.1124478e-04 9.9869072e-03 2.8421807e-03 2.3387438e-03 9.8402643e-01\n",
      " 6.9443200e-04]\n",
      "Gesture recognition percentage: 98.4%\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[1.14003284e-04 7.92349782e-03 2.34694267e-03 2.12183455e-03\n",
      " 9.86817718e-01 6.75939431e-04]\n",
      "Gesture recognition percentage: 98.68%\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[1.2229865e-04 7.1363873e-03 2.1738478e-03 2.0645342e-03 9.8779851e-01\n",
      " 7.0438115e-04]\n",
      "Gesture recognition percentage: 98.78%\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "[1.2959025e-04 6.8974877e-03 2.1054633e-03 2.0521118e-03 9.8806572e-01\n",
      " 7.4961432e-04]\n",
      "Gesture recognition percentage: 98.81%\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "[1.3722008e-04 6.5550846e-03 1.9968308e-03 2.0146726e-03 9.8849595e-01\n",
      " 8.0027967e-04]\n",
      "Gesture recognition percentage: 98.85%\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[1.4631002e-04 6.2735057e-03 1.9033825e-03 1.9881746e-03 9.8882550e-01\n",
      " 8.6311105e-04]\n",
      "Gesture recognition percentage: 98.88%\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "[1.5584951e-04 6.2191384e-03 1.8667052e-03 1.9949430e-03 9.8883140e-01\n",
      " 9.3198998e-04]\n",
      "Gesture recognition percentage: 98.88%\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "[1.6853907e-04 6.6064079e-03 1.9630045e-03 2.1189523e-03 9.8813581e-01\n",
      " 1.0072103e-03]\n",
      "Gesture recognition percentage: 98.81%\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "[2.3810544e-04 9.2479261e-03 2.8912975e-03 3.0201783e-03 9.8334724e-01\n",
      " 1.2551959e-03]\n",
      "Gesture recognition percentage: 98.33%\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[3.5312379e-04 9.4046304e-03 3.2532373e-03 3.7996583e-03 9.8169166e-01\n",
      " 1.4977142e-03]\n",
      "Gesture recognition percentage: 98.17%\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[5.3501944e-04 7.9205474e-03 3.2326602e-03 4.5868359e-03 9.8203444e-01\n",
      " 1.6904394e-03]\n",
      "Gesture recognition percentage: 98.2%\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[8.7300321e-04 5.6391559e-03 2.9374235e-03 5.4316069e-03 9.8330861e-01\n",
      " 1.8101851e-03]\n",
      "Gesture recognition percentage: 98.33%\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[0.00207085 0.00501369 0.00300974 0.00708345 0.9802306  0.00259171]\n",
      "Gesture recognition percentage: 98.02%\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "[0.00567265 0.00466682 0.00273233 0.0104357  0.97166485 0.00482757]\n",
      "Gesture recognition percentage: 97.17%\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[0.01568115 0.00530514 0.00311753 0.0186627  0.94641596 0.01081757]\n",
      "Gesture recognition percentage: 94.64%\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[0.04356093 0.00526666 0.00266806 0.02825231 0.8938085  0.02644358]\n",
      "Gesture recognition percentage: 89.38%\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "[0.10469838 0.00506198 0.00194594 0.03709582 0.78331155 0.06788632]\n",
      "Gesture recognition percentage: 78.33%\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "[0.2069473  0.00347869 0.00087948 0.03473447 0.5869266  0.1670335 ]\n",
      "Gesture recognition percentage: 58.69%\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[0.2882619  0.00255725 0.0004627  0.03230926 0.38231158 0.2940973 ]\n",
      "Gesture recognition percentage: 38.23%\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[2.9784679e-01 1.4011551e-03 1.7384242e-04 2.8104117e-02 2.2924758e-01\n",
      " 4.4322652e-01]\n",
      "Gesture recognition percentage: 44.32%\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "[2.1026976e-01 8.5187086e-04 7.3072792e-05 2.2365451e-02 1.2674792e-01\n",
      " 6.3969183e-01]\n",
      "Gesture recognition percentage: 63.97%\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "[1.8168260e-01 4.1869027e-04 2.8655075e-05 1.8487938e-02 6.6710562e-02\n",
      " 7.3267156e-01]\n",
      "Gesture recognition percentage: 73.27%\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[1.4046235e-01 2.6922539e-04 1.4969044e-05 1.4022878e-02 3.9532349e-02\n",
      " 8.0569828e-01]\n",
      "Gesture recognition percentage: 80.57%\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "[1.2590161e-01 1.5350872e-04 7.2185990e-06 1.1260153e-02 2.3246730e-02\n",
      " 8.3943075e-01]\n",
      "Gesture recognition percentage: 83.94%\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "[1.0687239e-01 1.0133804e-04 3.9991046e-06 8.7257521e-03 1.5558192e-02\n",
      " 8.6873835e-01]\n",
      "Gesture recognition percentage: 86.87%\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[1.10968776e-01 6.36109762e-05 2.28066574e-06 7.60910334e-03\n",
      " 1.06931515e-02 8.70662987e-01]\n",
      "Gesture recognition percentage: 87.07%\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[1.1501575e-01 4.7649144e-05 1.5617935e-06 6.7590531e-03 8.6870771e-03\n",
      " 8.6948889e-01]\n",
      "Gesture recognition percentage: 86.95%\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[1.2500779e-01 3.6558231e-05 1.1312469e-06 6.2647909e-03 7.4394173e-03\n",
      " 8.6125028e-01]\n",
      "Gesture recognition percentage: 86.13%\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "[1.3319573e-01 2.9057925e-05 8.4708950e-07 5.7743168e-03 6.4976397e-03\n",
      " 8.5450238e-01]\n",
      "Gesture recognition percentage: 85.45%\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[1.5782373e-01 2.3655046e-05 6.5998790e-07 5.5481642e-03 6.1174757e-03\n",
      " 8.3048636e-01]\n",
      "Gesture recognition percentage: 83.05%\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[1.6478944e-01 1.4593523e-05 3.4819317e-07 4.4280319e-03 5.0715324e-03\n",
      " 8.2569605e-01]\n",
      "Gesture recognition percentage: 82.57%\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[1.8234709e-01 1.8560891e-05 4.5673480e-07 4.8335637e-03 5.7872115e-03\n",
      " 8.0701309e-01]\n",
      "Gesture recognition percentage: 80.7%\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "[2.0945123e-01 1.0428721e-05 2.3372516e-07 4.4198367e-03 4.7060470e-03\n",
      " 7.8141230e-01]\n",
      "Gesture recognition percentage: 78.14%\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[2.0181747e-01 1.6201002e-05 3.5209879e-07 4.3229749e-03 5.8304672e-03\n",
      " 7.8801256e-01]\n",
      "Gesture recognition percentage: 78.8%\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[2.6992080e-01 1.1304062e-05 2.6993419e-07 5.2284491e-03 5.2691372e-03\n",
      " 7.1956998e-01]\n",
      "Gesture recognition percentage: 71.96%\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "[2.37939715e-01 1.38964915e-05 2.93445879e-07 4.23444575e-03\n",
      " 5.81600051e-03 7.51995683e-01]\n",
      "Gesture recognition percentage: 75.2%\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "[2.6349384e-01 1.1203707e-05 2.5616035e-07 4.7822478e-03 5.3476281e-03\n",
      " 7.2636491e-01]\n",
      "Gesture recognition percentage: 72.64%\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[2.3297657e-01 1.3529908e-05 2.9265260e-07 4.2831488e-03 5.7533402e-03\n",
      " 7.5697309e-01]\n",
      "Gesture recognition percentage: 75.7%\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[2.5551039e-01 1.1846247e-05 2.6997324e-07 4.7291066e-03 5.4999352e-03\n",
      " 7.3424846e-01]\n",
      "Gesture recognition percentage: 73.42%\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[2.4408300e-01 1.2763091e-05 2.8199705e-07 4.3383520e-03 5.6850463e-03\n",
      " 7.4588054e-01]\n",
      "Gesture recognition percentage: 74.59%\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[2.65125960e-01 1.25156885e-05 2.87713590e-07 4.75521339e-03\n",
      " 5.71367797e-03 7.24392354e-01]\n",
      "Gesture recognition percentage: 72.44%\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[2.2360691e-01 9.1712163e-06 1.8235365e-07 3.7162865e-03 4.8813992e-03\n",
      " 7.6778603e-01]\n",
      "Gesture recognition percentage: 76.78%\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "[1.5811934e-01 1.0133999e-05 1.8751189e-07 3.3437880e-03 4.7114380e-03\n",
      " 8.3381522e-01]\n",
      "Gesture recognition percentage: 83.38%\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[1.0662790e-01 9.9975468e-06 2.0286458e-07 3.2424026e-03 4.0711081e-03\n",
      " 8.8604838e-01]\n",
      "Gesture recognition percentage: 88.6%\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "[6.3459463e-02 1.2472481e-05 2.5423822e-07 2.7776242e-03 3.9253649e-03\n",
      " 9.2982483e-01]\n",
      "Gesture recognition percentage: 92.98%\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "[4.3547597e-02 1.4244951e-05 3.1825985e-07 2.7356800e-03 3.7411107e-03\n",
      " 9.4996101e-01]\n",
      "Gesture recognition percentage: 95.0%\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "[2.9945802e-02 2.1267175e-05 5.2417994e-07 2.6438490e-03 4.3481956e-03\n",
      " 9.6304041e-01]\n",
      "Gesture recognition percentage: 96.3%\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[2.5040694e-02 3.2450786e-05 9.6392171e-07 3.0322310e-03 5.5594612e-03\n",
      " 9.6633422e-01]\n",
      "Gesture recognition percentage: 96.63%\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[2.1658314e-02 5.8631049e-05 2.1228007e-06 3.5073229e-03 9.3039628e-03\n",
      " 9.6546960e-01]\n",
      "Gesture recognition percentage: 96.55%\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[3.1267848e-02 1.8367778e-04 9.2956907e-06 6.2613245e-03 2.3288686e-02\n",
      " 9.3898916e-01]\n",
      "Gesture recognition percentage: 93.9%\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[3.9996810e-02 2.5283676e-04 1.4653368e-05 7.5164540e-03 3.3723712e-02\n",
      " 9.1849554e-01]\n",
      "Gesture recognition percentage: 91.85%\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[3.6964610e-02 2.6449285e-04 1.4464118e-05 6.5259682e-03 3.3503685e-02\n",
      " 9.2272669e-01]\n",
      "Gesture recognition percentage: 92.27%\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[4.8040416e-02 2.5390665e-04 1.4251834e-05 7.7568986e-03 3.3407129e-02\n",
      " 9.1052741e-01]\n",
      "Gesture recognition percentage: 91.05%\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[4.1123785e-02 1.9571284e-04 1.0014693e-05 6.4488701e-03 2.8335372e-02\n",
      " 9.2388624e-01]\n",
      "Gesture recognition percentage: 92.39%\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[4.0565256e-02 2.0276124e-04 1.0538770e-05 6.8373573e-03 2.9310446e-02\n",
      " 9.2307365e-01]\n",
      "Gesture recognition percentage: 92.31%\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[5.2364107e-02 3.2467375e-04 1.9604360e-05 9.6698664e-03 4.1268319e-02\n",
      " 8.9635342e-01]\n",
      "Gesture recognition percentage: 89.64%\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[5.1802836e-02 2.7296678e-04 1.5962780e-05 8.8195466e-03 3.7321772e-02\n",
      " 9.0176690e-01]\n",
      "Gesture recognition percentage: 90.18%\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "[4.4217784e-02 2.3721177e-04 1.2712799e-05 7.4241203e-03 3.1495426e-02\n",
      " 9.1661274e-01]\n",
      "Gesture recognition percentage: 91.66%\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[4.9089141e-02 2.4833856e-04 1.3925000e-05 8.3544021e-03 3.3048265e-02\n",
      " 9.0924591e-01]\n",
      "Gesture recognition percentage: 90.92%\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[5.1865306e-02 2.9339537e-04 1.7044140e-05 9.0044914e-03 3.6337279e-02\n",
      " 9.0248245e-01]\n",
      "Gesture recognition percentage: 90.25%\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[4.72135134e-02 2.17091612e-04 1.19448105e-05 7.72619946e-03\n",
      " 3.09933722e-02 9.13837790e-01]\n",
      "Gesture recognition percentage: 91.38%\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[4.0225536e-02 2.4298462e-04 1.3201896e-05 7.3594037e-03 3.2785818e-02\n",
      " 9.1937304e-01]\n",
      "Gesture recognition percentage: 91.94%\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[4.4088822e-02 2.8263396e-04 1.7069653e-05 8.6826514e-03 4.0600911e-02\n",
      " 9.0632784e-01]\n",
      "Gesture recognition percentage: 90.63%\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[6.0166389e-02 6.7124580e-04 4.8756971e-05 1.3174361e-02 7.3202029e-02\n",
      " 8.5273725e-01]\n",
      "Gesture recognition percentage: 85.27%\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[8.7865800e-02 5.3136511e-04 3.8298662e-05 1.4785001e-02 6.7014195e-02\n",
      " 8.2976532e-01]\n",
      "Gesture recognition percentage: 82.98%\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[8.9747921e-02 3.6025932e-04 2.0176953e-05 1.1789091e-02 4.1301366e-02\n",
      " 8.5678113e-01]\n",
      "Gesture recognition percentage: 85.68%\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "[1.4710541e-01 1.6328142e-04 8.3985615e-06 1.2895566e-02 2.3099627e-02\n",
      " 8.1672770e-01]\n",
      "Gesture recognition percentage: 81.67%\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[1.8226723e-01 9.5960459e-05 4.2898146e-06 1.1547895e-02 1.4860234e-02\n",
      " 7.9122442e-01]\n",
      "Gesture recognition percentage: 79.12%\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[2.9902938e-01 5.0144423e-05 2.1526357e-06 1.1645916e-02 1.0612584e-02\n",
      " 6.7865986e-01]\n",
      "Gesture recognition percentage: 67.87%\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "[4.90117162e-01 2.87436123e-05 1.17680099e-06 1.07879955e-02\n",
      " 7.50596449e-03 4.91558909e-01]\n",
      "Gesture recognition percentage: 49.16%\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[6.6395575e-01 9.4622110e-06 3.3646126e-07 7.2328956e-03 4.2123175e-03\n",
      " 3.2458928e-01]\n",
      "Gesture recognition percentage: 66.4%\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[8.0122977e-01 7.0608771e-06 3.0222361e-07 6.3179592e-03 3.1636409e-03\n",
      " 1.8928128e-01]\n",
      "Gesture recognition percentage: 80.12%\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[9.1091734e-01 1.9719544e-06 1.1119702e-07 4.3651951e-03 1.3728237e-03\n",
      " 8.3342560e-02]\n",
      "Gesture recognition percentage: 91.09%\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[9.4111103e-01 1.0540072e-06 4.9857309e-08 2.8584762e-03 9.3388243e-04\n",
      " 5.5095654e-02]\n",
      "Gesture recognition percentage: 94.11%\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "[9.5220912e-01 5.9157952e-07 2.7543987e-08 2.2043474e-03 7.1355328e-04\n",
      " 4.4872340e-02]\n",
      "Gesture recognition percentage: 95.22%\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[9.5829099e-01 4.7168297e-07 1.9876044e-08 1.9387339e-03 6.3025771e-04\n",
      " 3.9139569e-02]\n",
      "Gesture recognition percentage: 95.83%\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[9.5173281e-01 4.1182659e-07 1.5282533e-08 1.7390059e-03 6.8788626e-04\n",
      " 4.5839909e-02]\n",
      "Gesture recognition percentage: 95.17%\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[9.2651713e-01 5.3031187e-07 1.5413677e-08 1.7625400e-03 9.5559558e-04\n",
      " 7.0764177e-02]\n",
      "Gesture recognition percentage: 92.65%\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[8.5900420e-01 8.1878761e-07 1.7574425e-08 1.9322331e-03 1.5537890e-03\n",
      " 1.3750897e-01]\n",
      "Gesture recognition percentage: 85.9%\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[6.0328519e-01 1.7458565e-06 2.0470546e-08 2.4868739e-03 2.9788846e-03\n",
      " 3.9124733e-01]\n",
      "Gesture recognition percentage: 60.33%\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[2.0719644e-01 2.7097224e-06 2.8670499e-08 2.2314764e-03 3.3617835e-03\n",
      " 7.8720754e-01]\n",
      "Gesture recognition percentage: 78.72%\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[3.9028220e-02 2.4073472e-06 2.3154785e-08 1.4494071e-03 2.1742391e-03\n",
      " 9.5734572e-01]\n",
      "Gesture recognition percentage: 95.73%\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[6.7954180e-03 4.1016392e-06 4.4066439e-08 9.6476317e-04 2.3188512e-03\n",
      " 9.8991686e-01]\n",
      "Gesture recognition percentage: 98.99%\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[3.4577001e-03 1.4632804e-05 2.5501595e-07 1.2046148e-03 8.0703860e-03\n",
      " 9.8725247e-01]\n",
      "Gesture recognition percentage: 98.73%\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[3.3925513e-03 4.5410017e-04 1.8526482e-05 3.0309905e-03 2.3939325e-01\n",
      " 7.5371057e-01]\n",
      "Gesture recognition percentage: 75.37%\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[5.6806050e-04 1.4418422e-03 2.0461454e-04 1.1403768e-03 9.4662946e-01\n",
      " 5.0015651e-02]\n",
      "Gesture recognition percentage: 94.66%\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[7.1102935e-05 1.4949046e-03 2.2134108e-04 4.4270707e-04 9.9296206e-01\n",
      " 4.8078913e-03]\n",
      "Gesture recognition percentage: 99.3%\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[1.9479101e-05 3.6123171e-03 4.6732838e-04 2.5941269e-04 9.9408865e-01\n",
      " 1.5528628e-03]\n",
      "Gesture recognition percentage: 99.41%\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[7.1998979e-06 1.3487836e-02 6.2492478e-04 1.8798186e-04 9.8448551e-01\n",
      " 1.2065285e-03]\n",
      "Gesture recognition percentage: 98.45%\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[3.0362867e-06 5.7951562e-02 1.0885516e-03 1.7196740e-04 9.3902761e-01\n",
      " 1.7572924e-03]\n",
      "Gesture recognition percentage: 93.9%\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[2.3018758e-06 4.5418623e-01 5.1971297e-03 2.8380373e-04 5.3634602e-01\n",
      " 3.9844909e-03]\n",
      "Gesture recognition percentage: 53.63%\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[7.1021361e-07 8.5424447e-01 1.2124581e-02 1.6837353e-04 1.3187538e-01\n",
      " 1.5866110e-03]\n",
      "Gesture recognition percentage: 85.42%\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[1.0920382e-07 9.6333051e-01 2.0159736e-02 4.7626818e-05 1.6192023e-02\n",
      " 2.6995686e-04]\n",
      "Gesture recognition percentage: 96.33%\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[1.6769356e-08 9.5905155e-01 3.7703902e-02 1.2806952e-05 3.1884029e-03\n",
      " 4.3338296e-05]\n",
      "Gesture recognition percentage: 95.91%\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "[2.6009275e-09 9.1405755e-01 8.5262887e-02 3.7067334e-06 6.6982990e-04\n",
      " 5.9664653e-06]\n",
      "Gesture recognition percentage: 91.41%\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[5.2987209e-10 8.1142461e-01 1.8842138e-01 1.2971004e-06 1.5191679e-04\n",
      " 9.3219080e-07]\n",
      "Gesture recognition percentage: 81.14%\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[1.2047249e-10 6.8119067e-01 3.1878024e-01 5.0617581e-07 2.8470411e-05\n",
      " 1.6407567e-07]\n",
      "Gesture recognition percentage: 68.12%\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[3.2641632e-11 5.2337545e-01 4.7661877e-01 2.2771852e-07 5.5864730e-06\n",
      " 2.9449060e-08]\n",
      "Gesture recognition percentage: 52.34%\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[1.1952205e-11 3.8134632e-01 6.1865211e-01 1.2483920e-07 1.4174516e-06\n",
      " 6.6136367e-09]\n",
      "Gesture recognition percentage: 61.87%\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[6.2303990e-12 2.7884960e-01 7.2114980e-01 8.3007414e-08 5.0790584e-07\n",
      " 2.0916318e-09]\n",
      "Gesture recognition percentage: 72.11%\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[3.8664592e-12 1.9681831e-01 8.0318141e-01 6.7049228e-08 2.1240294e-07\n",
      " 6.9826828e-10]\n",
      "Gesture recognition percentage: 80.32%\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[3.6477973e-12 1.5529549e-01 8.4470427e-01 7.5944172e-08 1.4922674e-07\n",
      " 3.9023682e-10]\n",
      "Gesture recognition percentage: 84.47%\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[3.0392670e-12 1.2032065e-01 8.7967914e-01 8.0442184e-08 1.0302940e-07\n",
      " 2.0294347e-10]\n",
      "Gesture recognition percentage: 87.97%\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "[3.7332607e-12 1.0197409e-01 8.9802569e-01 1.1851999e-07 1.0650458e-07\n",
      " 1.5512419e-10]\n",
      "Gesture recognition percentage: 89.8%\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[6.4433927e-12 9.6715100e-02 9.0328461e-01 2.2372981e-07 1.5665191e-07\n",
      " 1.7991128e-10]\n",
      "Gesture recognition percentage: 90.33%\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[2.3757588e-11 1.2196762e-01 8.7803119e-01 6.9148524e-07 5.0932056e-07\n",
      " 5.6815802e-10]\n",
      "Gesture recognition percentage: 87.8%\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "[1.2820409e-10 1.7339623e-01 8.2659864e-01 2.7157560e-06 2.4174205e-06\n",
      " 2.8959661e-09]\n",
      "Gesture recognition percentage: 82.66%\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "[2.3190854e-09 3.0861297e-01 6.9132590e-01 2.6265507e-05 3.4812008e-05\n",
      " 4.8289685e-08]\n",
      "Gesture recognition percentage: 69.13%\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "[2.9487776e-07 5.2445823e-01 4.7240803e-01 5.7577918e-04 2.5538390e-03\n",
      " 3.8729413e-06]\n",
      "Gesture recognition percentage: 52.45%\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "[3.6997221e-06 6.5389550e-01 3.2394525e-01 2.2693048e-03 1.9836038e-02\n",
      " 5.0227023e-05]\n",
      "Gesture recognition percentage: 65.39%\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[3.2857868e-05 7.1079415e-01 1.8871593e-01 6.8109487e-03 9.3169153e-02\n",
      " 4.7691452e-04]\n",
      "Gesture recognition percentage: 71.08%\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[1.1546109e-04 5.4983032e-01 1.0045451e-01 1.1546205e-02 3.3603564e-01\n",
      " 2.0179758e-03]\n",
      "Gesture recognition percentage: 54.98%\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "[1.8692040e-04 1.0558798e-01 1.9283202e-02 7.3997406e-03 8.6522543e-01\n",
      " 2.3166656e-03]\n",
      "Gesture recognition percentage: 86.52%\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "[1.5598664e-04 3.0020088e-02 5.1274518e-03 3.5709545e-03 9.5921129e-01\n",
      " 1.9141943e-03]\n",
      "Gesture recognition percentage: 95.92%\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[1.2704816e-04 1.6585128e-02 2.9663299e-03 2.4669289e-03 9.7639728e-01\n",
      " 1.4572861e-03]\n",
      "Gesture recognition percentage: 97.64%\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "[1.13127106e-04 1.11901099e-02 2.11616606e-03 1.94003072e-03\n",
      " 9.83412981e-01 1.22762297e-03]\n",
      "Gesture recognition percentage: 98.34%\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "[1.0241984e-04 8.0017531e-03 1.5252386e-03 1.5147799e-03 9.8772007e-01\n",
      " 1.1356110e-03]\n",
      "Gesture recognition percentage: 98.77%\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "[9.0361034e-05 6.5381201e-03 1.2057321e-03 1.2383105e-03 9.8984712e-01\n",
      " 1.0804017e-03]\n",
      "Gesture recognition percentage: 98.98%\n"
     ]
    }
   ],
   "source": [
    "# 1. New detection variables\n",
    "sequence = []\n",
    "sentence = []\n",
    "threshold = 0.95\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "# Set mediapipe model \n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "\n",
    "        # Read feed\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Make detections\n",
    "        image, results = mediapipe_detection(frame, holistic)\n",
    "        #print(results)\n",
    "        \n",
    "        # Draw landmarks\n",
    "        draw_styled_landmarks(image, results)\n",
    "        \n",
    "        # 2. Prediction logic\n",
    "        keypoints = extract_keypoints(results)\n",
    "#         sequence.insert(0,keypoints)\n",
    "#         sequence = sequence[:30]\n",
    "        sequence.append(keypoints)\n",
    "        sequence = sequence[-30:]\n",
    "        \n",
    "        if len(sequence) == 30:\n",
    "            res = model.predict(np.expand_dims(sequence, axis=0))[0]\n",
    "            print(res)\n",
    "            #print(actions[np.argmax(res)])\n",
    "            \n",
    "            # Calculate recognition percentage\n",
    "            recognition_percentage = round(100 * res[np.argmax(res)], 2)\n",
    "            print(f\"Gesture recognition percentage: {recognition_percentage}%\")\n",
    "            \n",
    "        #3. Viz logic\n",
    "            if res[np.argmax(res)] > threshold: \n",
    "                if len(sentence) > 0: \n",
    "                    if actions[np.argmax(res)] != sentence[-1]:\n",
    "                        sentence.append(actions[np.argmax(res)])\n",
    "                else:\n",
    "                    sentence.append(actions[np.argmax(res)])\n",
    "\n",
    "            if len(sentence) > 5: \n",
    "                sentence = sentence[-5:]\n",
    "\n",
    "            # Viz probabilities\n",
    "            #print(res)\n",
    "            #print(colors)\n",
    "            image = prob_viz(res, actions, image, colors)\n",
    "            \n",
    "        cv2.rectangle(image, (0,0), (640, 40), (245, 117, 16), -1)\n",
    "        cv2.putText(image, ' '.join(sentence), (3,30), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "        \n",
    "        # Show to screen\n",
    "        cv2.imshow('OpenCV Feed', image)\n",
    "\n",
    "        # Break gracefully\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
